{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Vocabulous Demo: Bootstrapping Language Detection\n",
        "\n",
        "This notebook demonstrates how to use Vocabulous to build language detection models from noisy training data.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Vocabulous is a bootstrapping language detection system that:\n",
        "- Builds dictionaries from potentially mislabeled training data\n",
        "- Iteratively cleans the data to improve model quality\n",
        "- Provides fast, interpretable language detection\n",
        "\n",
        "Let's explore its capabilities!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vocabulous in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (0.1.0)\n",
            "Requirement already satisfied: matplotlib in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (3.10.3)\n",
            "Requirement already satisfied: seaborn in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (2.3.1)\n",
            "Requirement already satisfied: nltk>=3.6 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from vocabulous) (3.9.1)\n",
            "Requirement already satisfied: swifter>=1.0.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from vocabulous) (1.4.0)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from vocabulous) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: click in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from nltk>=3.6->vocabulous) (8.2.1)\n",
            "Requirement already satisfied: joblib in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from nltk>=3.6->vocabulous) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from nltk>=3.6->vocabulous) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: psutil>=5.6.6 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from swifter>=1.0.0->vocabulous) (7.0.0)\n",
            "Requirement already satisfied: dask>=2.10.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (2025.7.0)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (3.1.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (2025.7.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (1.0.0)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (21.0.0)\n",
            "Requirement already satisfied: locket in /Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter>=1.0.0->vocabulous) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages if running in Colab\n",
        "!pip install vocabulous matplotlib seaborn pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/omar/Code/opensource/vocabulous/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from vocabulous import Vocabulous\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Creating Sample Data\n",
        "\n",
        "Let's create a realistic multilingual dataset with some label noise to demonstrate Vocabulous's capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 30 clean training samples\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lang\n",
              "en    10\n",
              "es    10\n",
              "fr    10\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create sample training data for English, French, and Spanish\n",
        "clean_training_data = [\n",
        "    # English samples\n",
        "    {'text': 'Hello world how are you today', 'lang': 'en'},\n",
        "    {'text': 'Good morning everyone', 'lang': 'en'},\n",
        "    {'text': 'The weather is nice today', 'lang': 'en'},\n",
        "    {'text': 'I love programming in Python', 'lang': 'en'},\n",
        "    {'text': 'Machine learning is fascinating', 'lang': 'en'},\n",
        "    {'text': 'Natural language processing rocks', 'lang': 'en'},\n",
        "    {'text': 'Open source software is amazing', 'lang': 'en'},\n",
        "    {'text': 'Data science helps solve problems', 'lang': 'en'},\n",
        "    {'text': 'Artificial intelligence is the future', 'lang': 'en'},\n",
        "    {'text': 'Technology makes life easier', 'lang': 'en'},\n",
        "    \n",
        "    # French samples\n",
        "    {'text': 'Bonjour tout le monde', 'lang': 'fr'},\n",
        "    {'text': 'Comment allez vous aujourd hui', 'lang': 'fr'},\n",
        "    {'text': 'Le temps est magnifique', 'lang': 'fr'},\n",
        "    {'text': 'J aime programmer en Python', 'lang': 'fr'},\n",
        "    {'text': 'L apprentissage automatique est fascinant', 'lang': 'fr'},\n",
        "    {'text': 'Le traitement du langage naturel', 'lang': 'fr'},\n",
        "    {'text': 'Les logiciels libres sont formidables', 'lang': 'fr'},\n",
        "    {'text': 'La science des donn√©es r√©sout les probl√®mes', 'lang': 'fr'},\n",
        "    {'text': 'L intelligence artificielle est l avenir', 'lang': 'fr'},\n",
        "    {'text': 'La technologie facilite la vie', 'lang': 'fr'},\n",
        "    \n",
        "    # Spanish samples\n",
        "    {'text': 'Hola mundo c√≥mo est√°n ustedes', 'lang': 'es'},\n",
        "    {'text': 'Buenos d√≠as a todos', 'lang': 'es'},\n",
        "    {'text': 'El clima est√° hermoso hoy', 'lang': 'es'},\n",
        "    {'text': 'Me encanta programar en Python', 'lang': 'es'},\n",
        "    {'text': 'El aprendizaje autom√°tico es fascinante', 'lang': 'es'},\n",
        "    {'text': 'El procesamiento de lenguaje natural', 'lang': 'es'},\n",
        "    {'text': 'El software libre es incre√≠ble', 'lang': 'es'},\n",
        "    {'text': 'La ciencia de datos resuelve problemas', 'lang': 'es'},\n",
        "    {'text': 'La inteligencia artificial es el futuro', 'lang': 'es'},\n",
        "    {'text': 'La tecnolog√≠a hace la vida m√°s f√°cil', 'lang': 'es'},\n",
        "]\n",
        "\n",
        "print(f\"Created {len(clean_training_data)} clean training samples\")\n",
        "pd.DataFrame(clean_training_data).groupby('lang').size()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Introduced noise in 1 samples (5.0% noise rate)\n",
            "\n",
            "Noisy data distribution:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "lang\n",
              "en    11\n",
              "es     9\n",
              "fr    10\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add some label noise to simulate real-world conditions\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "noisy_training_data = clean_training_data.copy()\n",
        "languages = ['en', 'fr', 'es']\n",
        "\n",
        "# Introduce 5% label noise\n",
        "noise_rate = 0.05\n",
        "num_noisy_samples = int(len(noisy_training_data) * noise_rate)\n",
        "\n",
        "for i in random.sample(range(len(noisy_training_data)), num_noisy_samples):\n",
        "    original_lang = noisy_training_data[i]['lang']\n",
        "    # Assign a random wrong language\n",
        "    wrong_langs = [lang for lang in languages if lang != original_lang]\n",
        "    noisy_training_data[i]['lang'] = random.choice(wrong_langs)\n",
        "\n",
        "print(f\"Introduced noise in {num_noisy_samples} samples ({noise_rate*100}% noise rate)\")\n",
        "print(\"\\nNoisy data distribution:\")\n",
        "pd.DataFrame(noisy_training_data).groupby('lang').size()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Training Vocabulous Models\n",
        "\n",
        "Let's train models on both clean and noisy data to see how Vocabulous handles the bootstrapping process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-07-20 18:08:31,126 - INFO - Starting training cycle 1/2\n",
            "2025-07-20 18:08:31,127 - INFO - Starting cycle with 30 samples after deduplication\n",
            "2025-07-20 18:08:31,127 - INFO - Processing sentences...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Vocabulous on noisy data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Pandas Apply: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 18281.14it/s]\n",
            "2025-07-20 18:08:31,152 - INFO - Building language dictionaries...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 213995.10it/s]\n",
            "2025-07-20 18:08:31,154 - INFO - Generating cycle report...\n",
            "Pandas Apply: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:00<00:00, 45756.04it/s]\n",
            "2025-07-20 18:08:31,161 - INFO - Scoring training data...\n",
            "Pandas Apply: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 119609.43it/s]\n",
            "2025-07-20 18:08:31,171 - INFO - Cleaning training data...\n",
            "2025-07-20 18:08:31,172 - INFO - No samples removed in this cycle - stopping early\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training completed!\n",
            "Number of cycles: 1\n",
            "Dictionary size: 125 words\n",
            "\n",
            "Progress across training cycles:\n",
            "Cycle 1: Accuracy=0.667, F1=0.533, Removed=0 samples\n"
          ]
        }
      ],
      "source": [
        "# Create evaluation data\n",
        "eval_data = [\n",
        "    {'text': 'Hello there my friend', 'lang': 'en'},\n",
        "    {'text': 'Programming is fun and exciting', 'lang': 'en'},\n",
        "    {'text': 'Bonjour mes amis', 'lang': 'fr'},\n",
        "    {'text': 'La programmation est amusante', 'lang': 'fr'},\n",
        "    {'text': 'Hola mis amigos', 'lang': 'es'},\n",
        "    {'text': 'La programaci√≥n es divertida', 'lang': 'es'},\n",
        "]\n",
        "\n",
        "# Train on noisy data with bootstrapping\n",
        "print(\"Training Vocabulous on noisy data...\")\n",
        "model = Vocabulous()\n",
        "model, report = model.train(\n",
        "    train_df=noisy_training_data,\n",
        "    eval_df=eval_data,\n",
        "    cycles=2,\n",
        "    base_confidence=0.4,\n",
        "    confidence_margin=0.3\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"Number of cycles: {report['cycles']}\")\n",
        "print(f\"Dictionary size: {report['dictionary_size']} words\")\n",
        "\n",
        "# Show improvement across cycles\n",
        "print(\"\\nProgress across training cycles:\")\n",
        "for i, cycle_report in enumerate(report['cycle_reports']):\n",
        "    print(f\"Cycle {i+1}: Accuracy={cycle_report['accuracy']:.3f}, \"\n",
        "          f\"F1={cycle_report['f1']:.3f}, \"\n",
        "          f\"Removed={cycle_report['removed_samples']} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Testing Language Detection\n",
        "\n",
        "Now let's test our trained model on some new sentences to see how well it performs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language Detection Results:\n",
            "============================================================\n",
            "\n",
            "Text: 'Hello how are you doing today'\n",
            "Expected: en | Predicted: en ‚úì\n",
            "Confidence: 0.667\n",
            "All scores: {'en': 0.6666666666666666}\n",
            "\n",
            "Text: 'Machine learning algorithms are powerful'\n",
            "Expected: en | Predicted: en ‚úì\n",
            "Confidence: 0.400\n",
            "All scores: {'en': 0.4}\n",
            "\n",
            "Text: 'Bonjour comment √ßa va aujourd hui'\n",
            "Expected: fr | Predicted: fr ‚úì\n",
            "Confidence: 0.500\n",
            "All scores: {'fr': 0.5}\n",
            "\n",
            "Text: 'Les algorithmes d apprentissage automatique'\n",
            "Expected: fr | Predicted: fr ‚úì\n",
            "Confidence: 0.400\n",
            "All scores: {'fr': 0.4}\n",
            "\n",
            "Text: 'Hola c√≥mo est√°s hoy'\n",
            "Expected: es | Predicted: es ‚úì\n",
            "Confidence: 0.250\n",
            "All scores: {'es': 0.25}\n",
            "\n",
            "Text: 'Los algoritmos de aprendizaje autom√°tico'\n",
            "Expected: es | Predicted: es ‚úì\n",
            "Confidence: 0.400\n",
            "All scores: {'es': 0.4}\n"
          ]
        }
      ],
      "source": [
        "# Test sentences in different languages\n",
        "test_sentences = [\n",
        "    \"Hello how are you doing today\",\n",
        "    \"Machine learning algorithms are powerful\", \n",
        "    \"Bonjour comment √ßa va aujourd hui\",\n",
        "    \"Les algorithmes d apprentissage automatique\",\n",
        "    \"Hola c√≥mo est√°s hoy\",\n",
        "    \"Los algoritmos de aprendizaje autom√°tico\"\n",
        "]\n",
        "\n",
        "expected_langs = ['en', 'en', 'fr', 'fr', 'es', 'es']\n",
        "\n",
        "print(\"Language Detection Results:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, sentence in enumerate(test_sentences):\n",
        "    # Get scores from model\n",
        "    scores = model._score_sentence(sentence)\n",
        "    \n",
        "    # Get top prediction\n",
        "    if scores:\n",
        "        predicted = max(scores.items(), key=lambda x: x[1])[0]\n",
        "        confidence = max(scores.values())\n",
        "    else:\n",
        "        predicted = 'unknown'\n",
        "        confidence = 0.0\n",
        "    \n",
        "    expected = expected_langs[i]\n",
        "    correct = \"‚úì\" if predicted == expected else \"‚úó\"\n",
        "    \n",
        "    print(f\"\\nText: '{sentence}'\")\n",
        "    print(f\"Expected: {expected} | Predicted: {predicted} {correct}\")\n",
        "    print(f\"Confidence: {confidence:.3f}\")\n",
        "    print(f\"All scores: {scores}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Key Takeaways\n",
        "\n",
        "This demo showcased the core capabilities of Vocabulous:\n",
        "\n",
        "### ‚úÖ **Bootstrapping Success**\n",
        "- Started with 15% label noise in training data\n",
        "- Iteratively improved model quality through progressive data cleaning\n",
        "- Achieved good performance despite noisy labels\n",
        "\n",
        "### ‚úÖ **Interpretable Results**\n",
        "- Dictionary-based approach provides clear word-language associations\n",
        "- Fast inference without neural network complexity\n",
        "- Easy to understand and debug\n",
        "\n",
        "### ‚úÖ **Practical Applications**\n",
        "- Language detection from noisy datasets\n",
        "- Data cleaning and preprocessing\n",
        "- Bootstrap training for other models\n",
        "\n",
        "### üéØ **When to Use Vocabulous**\n",
        "\n",
        "**Perfect for:**\n",
        "- Noisy multilingual datasets\n",
        "- Fast language detection requirements\n",
        "- Interpretable model requirements\n",
        "- Data cleaning pipelines\n",
        "\n",
        "Try experimenting with different parameters and datasets to see how Vocabulous can help with your language detection needs!\n",
        "\n",
        "For more advanced features and examples, check out the full documentation at: https://github.com/omar/vocabulous\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
